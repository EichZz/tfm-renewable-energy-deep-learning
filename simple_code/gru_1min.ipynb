{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "        print(\"Setting GPU Memory Growth...\")\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        \n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_keras_history import plot_history\n",
    "import sklearn.metrics as metrics\n",
    "import os as os\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import kerastuner as kt\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization\n",
    "\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Panda version:\", pd.__version__)\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(\"Physical devices: \", tf.config.list_physical_devices())\n",
    "# Se va a habilitar la dedicacion dinamica de memoria para que la GPU vaya asignando recursos al proceso conforme los vaya necesitando\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Build with CUDA: \", tf.test.is_built_with_cuda())\n",
    "\n",
    "# Insantes de tiempo futuros a predecir\n",
    "numPredictions = 600\n",
    "\n",
    "# Porcentaje del conjunto de test\n",
    "test_size = 0.3\n",
    "# Porcentaje del conjunto de validacion\n",
    "val_size = 0.3\n",
    "\n",
    "# Establecer objetivo (Name of model metric to minimize or maximize, e.g. \"val_accuracy\"). el \"val_\" hace referencia a que se coge la métrica en el subconjunto de validación\n",
    "\n",
    "# obje = kerastuner.Objective('val_mean_absolute_percentage_error', 'min')\n",
    "\n",
    "# Epocas\n",
    "epchs=1000\n",
    "# Tamaño del batch\n",
    "batch = 1024\n",
    "# Dimensionalidad del espacio de output\n",
    "units = 16\n",
    "\n",
    "# Establecer medida de loss\n",
    "loss=\"mean_squared_error\"\n",
    "\n",
    "# Model metrics\n",
    "modelMetrics = [keras.metrics.MAE, keras.metrics.RMSE]\n",
    "\n",
    "# Establecer learning rate\n",
    "lr = [0.0, 1e-2, 1e-3, 1e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:/Users/hecto/Documents/Master/TFM/tfm-renewable-energy-deep-learning/data/2015_1min.xlsx\", \n",
    "                    header=None,\n",
    "                    engine='openpyxl')[0]\n",
    "\n",
    "df2 = pd.read_excel(\"C:/Users/hecto/Documents/Master/TFM/tfm-renewable-energy-deep-learning/data/2016_1min.xlsx\",\n",
    "                    header = None, \n",
    "                    engine = 'openpyxl')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing: each row will contain the 600 measures for each day , and the 600 measures for the following day\n",
    "X = pd.DataFrame(np.array(df).reshape(-1, numPredictions))\n",
    "Y = pd.DataFrame.copy(X)\n",
    "\n",
    "Y.columns = [\"col_{}\".format(i) for i in range(601, 1201)]\n",
    "Y = Y.drop(0)\n",
    "Y = Y.reset_index(drop=True)\n",
    "Y.loc[len(Y)] = np.zeros(numPredictions)\n",
    "\n",
    "# Last row is deleted because it is the one used for the real prediction, \n",
    "# it is not useful for the training of the model. \n",
    "X.drop(X.tail(1).index,inplace=True)\n",
    "Y.drop(Y.tail(1).index,inplace=True)\n",
    "\n",
    "print(\"X Preproccessed shape: \", X.shape)\n",
    "print(\"Y Preproccessed shape: \", Y.shape)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "#  Uncomment in order to normalize data\n",
    "# # Data Normalization\n",
    "# scaler = MinMaxScaler()\n",
    "# XNormalized = pd.DataFrame(scaler.fit_transform(X), columns=[\"col_{}\".format(i) for i in range(1, 601)])\n",
    "# YNormalized = pd.DataFrame(scaler.fit_transform(Y), columns=[\"col_{}\".format(i) for i in range(601, 1201)])\n",
    "\n",
    "dfPreproccessed = pd.concat([X, Y], axis=1)\n",
    "\n",
    "print(\"DataFrame Preproccessed:\")\n",
    "print(dfPreproccessed)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, \n",
    "                                                Y, \n",
    "                                                test_size = test_size, \n",
    "                                                random_state = 0, \n",
    "                                                shuffle=False)\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(xTrain, \n",
    "                                            yTrain, \n",
    "                                            test_size = val_size, \n",
    "                                            random_state = 0,\n",
    "                                            shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    def build_model(hp):\n",
    "\n",
    "        # Model definition\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(GRU(\n",
    "                units = units ,\n",
    "                input_shape = (xTrain.shape[1], 1),\n",
    "            ))\n",
    "        model.add(Dropout(rate = 0.25))\n",
    "        model.add(Dense(numPredictions, activation=\"sigmoid\"))\n",
    "\n",
    "        print(\"Model Summary: \", model.summary())\n",
    "\n",
    "        # Set Epsilon to 1, in order to fix huge MAPE values.\n",
    "        keras.backend.set_epsilon(1)\n",
    "\n",
    "        # Model compilation\n",
    "        model.compile(loss = loss,\n",
    "                    optimizer = \"adam\",\n",
    "                    metrics = modelMetrics)\n",
    "\n",
    "        history = model.fit(\n",
    "            np.reshape(xTrain.values, (xTrain.shape[0], xTrain.shape[1], 1)),\n",
    "            yTrain,\n",
    "            epochs=epchs,\n",
    "            batch_size=batch,\n",
    "            validation_data=(np.reshape(xVal.values, (xVal.shape[0], xVal.shape[1], 1)), yVal))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation loss curves\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Model evaluation with validation data\n",
    "score = model.evaluate(np.reshape(xVal.values, (xVal.shape[0], xVal.shape[1], 1)), yVal)\n",
    "print('Score:', score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
