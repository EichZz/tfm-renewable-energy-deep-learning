{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SETTING MEMORY GROWTH\n",
      "TF version: 2.1.0\n",
      "Panda version: 1.1.5\n",
      "Physical devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Default GPU Device: /device:GPU:0\n",
      "Num GPUs Available:  1\n",
      "Build with CUDA:  True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "        print(\"SETTING MEMORY GROWTH\")\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        \n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_keras_history import plot_history\n",
    "import sklearn.metrics as metrics\n",
    "import os as os\n",
    "\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.python.client import device_lib\n",
    "# import keras_tuner as kerastuner\n",
    "# from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Panda version:\", pd.__version__)\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(\"Physical devices: \", tf.config.list_physical_devices())\n",
    "# Se va a habilitar la dedicacion dinamica de memoria para que la GPU vaya asignando recursos al proceso conforme los vaya necesitando\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "#print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Build with CUDA: \", tf.test.is_built_with_cuda())\n",
    "\n",
    "\n",
    "# Historico de datos para realizar la predicción\n",
    "W = 729\n",
    "# Insantes de tiempo futuros a predecir\n",
    "H = 10\n",
    "\n",
    "# Porcentaje del conjunto de test\n",
    "test_size = 0.3\n",
    "# Porcentaje del conjunto de validacion\n",
    "val_size = 0.3\n",
    "\n",
    "# Establecer objetivo (Name of model metric to minimize or maximize, e.g. \"val_accuracy\"). el \"val_\" hace referencia a que se coge la métrica en el subconjunto de validación\n",
    "\n",
    "# obje = kerastuner.Objective('val_mean_absolute_percentage_error', 'min')\n",
    "\n",
    "# Epocas\n",
    "epchs=10\n",
    "# Tamaño del batch\n",
    "batch = 1024\n",
    "# Nodos internos\n",
    "hidden_nodes = 10\n",
    "\n",
    "# Establecer minimo y maximo de capas y el valor por defecto\n",
    "minLayers = 1\n",
    "maxLayers = 10\n",
    "defaultLayers = 3\n",
    "\n",
    "# Establecer medida de loss\n",
    "loss=\"mean_squared_error\"\n",
    "#loss=\"mean_absolute_percentage_error\"\n",
    "\n",
    "# Establecer learning rate\n",
    "lr = [0.0, 1e-2, 1e-3, 1e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         167.705\n",
      "1         156.535\n",
      "2         147.035\n",
      "3         131.875\n",
      "4         117.075\n",
      "           ...   \n",
      "218995    219.170\n",
      "218996    216.610\n",
      "218997    165.905\n",
      "218998    174.030\n",
      "218999    204.255\n",
      "Name: 0, Length: 219000, dtype: float64\n",
      "Row for predicting:             0        1        2        3        4        5       6        7  \\\n",
      "364  196.285  262.135  232.035  216.995  290.575  179.135  218.63  248.695   \n",
      "\n",
      "           8       9  ...  col_1191  col_1192  col_1193  col_1194  col_1195  \\\n",
      "364  236.825  210.13  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "     col_1196  col_1197  col_1198  col_1199  col_1200  \n",
      "364       0.0       0.0       0.0       0.0       0.0  \n",
      "\n",
      "[1 rows x 1200 columns]\n",
      "DataFrame Preproccessed (Not Normalized):\n",
      "           0        1        2        3        4        5        6        7  \\\n",
      "0    167.705  156.535  147.035  131.875  117.075  107.105  100.345   92.940   \n",
      "1     87.295   80.875   78.365   80.495   81.760   82.825  126.365  301.410   \n",
      "2     34.420   40.800   44.375   45.200   44.685   46.235   43.175   41.280   \n",
      "3    329.160  332.735  342.305  355.240  362.155  366.555  367.610  368.375   \n",
      "4    154.450  147.610  148.305  144.395  143.120  154.575  202.250  269.090   \n",
      "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "360  154.395  158.445  163.025  166.155  163.665  158.595  155.515  155.680   \n",
      "361  214.265  185.680  175.200  200.755  217.365  179.530  188.075  325.840   \n",
      "362  151.390  153.500  153.300  153.665  160.050  171.835  185.110  195.305   \n",
      "363  311.870  315.580  319.050  321.925  326.095  330.110  333.945  337.750   \n",
      "364  196.285  262.135  232.035  216.995  290.575  179.135  218.630  248.695   \n",
      "\n",
      "           8        9  ...  col_1191  col_1192  col_1193  col_1194  col_1195  \\\n",
      "0     86.780   78.980  ...   106.270   103.290   101.675    99.770    93.155   \n",
      "1    311.850  214.005  ...   298.540   297.300   293.995   293.610   299.875   \n",
      "2     52.390   73.080  ...   292.020   279.725   270.725   273.350   281.895   \n",
      "3    372.780  380.090  ...   133.155   132.140   130.860   130.145   128.765   \n",
      "4    384.470  289.525  ...   279.435   276.105   271.885   268.050   266.350   \n",
      "..       ...      ...  ...       ...       ...       ...       ...       ...   \n",
      "360  157.045  159.740  ...    50.670    51.775    55.295    61.840    69.285   \n",
      "361  390.195  421.885  ...    62.410    63.465    68.950    76.385    82.820   \n",
      "362  198.730  205.515  ...   167.055    82.775    72.525    70.570    64.405   \n",
      "363  340.110  343.585  ...   237.135   126.445   110.230   201.945   223.950   \n",
      "364  236.825  210.130  ...     0.000     0.000     0.000     0.000     0.000   \n",
      "\n",
      "     col_1196  col_1197  col_1198  col_1199  col_1200  \n",
      "0      85.565    78.535    78.050    79.880    98.920  \n",
      "1     306.510   312.100   305.925   284.280   273.105  \n",
      "2     280.150   275.000   269.000   263.815   220.825  \n",
      "3     128.010   127.095   125.330   122.985   121.310  \n",
      "4     263.895   260.535   258.100   255.610   254.765  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "360    73.220    73.830    75.340    80.265    95.295  \n",
      "361    87.900    93.490    97.600    93.530    85.120  \n",
      "362    62.650    68.250   125.030   181.920   201.510  \n",
      "363   219.170   216.610   165.905   174.030   204.255  \n",
      "364     0.000     0.000     0.000     0.000     0.000  \n",
      "\n",
      "[365 rows x 1200 columns]\n",
      "---------------------------------------------\n",
      "364\n",
      "X Preproccessed:\n",
      "        col_1     col_2     col_3     col_4     col_5     col_6     col_7  \\\n",
      "0    0.384402  0.384378  0.368548  0.283785  0.283110  0.248905  0.224875   \n",
      "1    0.200009  0.198420  0.196395  0.173219  0.197668  0.192464  0.283259   \n",
      "2    0.078758  0.099923  0.111184  0.097267  0.107967  0.107407  0.096596   \n",
      "3    0.754644  0.817446  0.858081  0.764450  0.876065  0.852017  0.824568   \n",
      "4    0.354006  0.362442  0.371732  0.310727  0.346124  0.359252  0.453531   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "360  0.353880  0.389073  0.408634  0.357553  0.395831  0.368597  0.348666   \n",
      "361  0.491171  0.456011  0.439156  0.432010  0.525755  0.417262  0.421725   \n",
      "362  0.346989  0.376919  0.384254  0.330676  0.387085  0.399375  0.415072   \n",
      "363  0.714995  0.775282  0.799782  0.692759  0.788820  0.767298  0.749030   \n",
      "364  0.449940  0.643924  0.581639  0.466957  0.702882  0.416344  0.490284   \n",
      "\n",
      "        col_8     col_9    col_10  ...   col_591   col_592   col_593  \\\n",
      "0    0.217096  0.205748  0.185735  ...  0.597747  0.683302  0.742367   \n",
      "1    0.704187  0.739494  0.503269  ...  0.279349  0.277594  0.300658   \n",
      "2    0.096392  0.124194  0.171860  ...  0.784764  0.799000  0.869358   \n",
      "3    0.860651  0.883988  0.893846  ...  0.767625  0.751767  0.800547   \n",
      "4    0.628671  0.911710  0.680867  ...  0.350021  0.355129  0.386959   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "360  0.363688  0.372380  0.375656  ...  0.238158  0.238854  0.255415   \n",
      "361  0.761268  0.925287  0.992134  ...  0.133195  0.139146  0.163510   \n",
      "362  0.456272  0.471234  0.483303  ...  0.164056  0.170564  0.203889   \n",
      "363  0.789096  0.806512  0.807998  ...  0.439133  0.222460  0.214460   \n",
      "364  0.581018  0.561575  0.494156  ...  0.623351  0.339824  0.325955   \n",
      "\n",
      "      col_594   col_595   col_596   col_597   col_598   col_599   col_600  \n",
      "0    0.661950  0.532907  0.459079  0.421802  0.379047  0.292388  0.350159  \n",
      "1    0.322718  0.297691  0.262574  0.250359  0.255128  0.280991  0.358198  \n",
      "2    0.949718  0.958297  0.940590  0.994931  1.000000  1.000000  0.988938  \n",
      "3    0.884184  0.900839  0.859699  0.876662  0.879300  0.928011  0.799627  \n",
      "4    0.420970  0.411488  0.392825  0.405161  0.409676  0.432619  0.439274  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "360  0.276172  0.273149  0.264262  0.281424  0.294893  0.323783  0.330642  \n",
      "361  0.200029  0.221411  0.224691  0.235360  0.246270  0.282345  0.345072  \n",
      "362  0.247077  0.264664  0.269739  0.298033  0.319032  0.329007  0.308227  \n",
      "363  0.228267  0.205816  0.192255  0.217571  0.408695  0.639932  0.729686  \n",
      "364  0.653216  0.715667  0.672569  0.690522  0.542306  0.612178  0.739626  \n",
      "\n",
      "[365 rows x 600 columns]\n",
      "---------------------------------------------\n",
      "Y Preproccessed:\n",
      "      col_601   col_602   col_603   col_604   col_605   col_606   col_607  \\\n",
      "0    0.200147  0.198705  0.196445  0.173219  0.197784  0.192520  0.283460   \n",
      "1    0.078917  0.100243  0.111239  0.097267  0.108097  0.107470  0.096849   \n",
      "2    0.754686  0.817511  0.858090  0.764450  0.876083  0.852027  0.824617   \n",
      "3    0.354117  0.362669  0.371771  0.310727  0.346219  0.359297  0.453684   \n",
      "4    0.626864  0.688558  0.706993  0.609662  0.693260  0.665284  0.620913   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "360  0.491259  0.456205  0.439191  0.432010  0.525824  0.417303  0.421887   \n",
      "361  0.347101  0.377141  0.384292  0.330676  0.387174  0.399417  0.415236   \n",
      "362  0.715044  0.775362  0.799794  0.692759  0.788850  0.767314  0.749100   \n",
      "363  0.450035  0.644051  0.581665  0.466957  0.702925  0.416385  0.490427   \n",
      "364  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "      col_608   col_609   col_610  ...  col_1191  col_1192  col_1193  \\\n",
      "0    0.704204  0.739507  0.503269  ...  0.279349  0.277594  0.300658   \n",
      "1    0.096445  0.124235  0.171860  ...  0.784764  0.799000  0.869358   \n",
      "2    0.860659  0.883993  0.893846  ...  0.767625  0.751767  0.800547   \n",
      "3    0.628693  0.911714  0.680867  ...  0.350021  0.355129  0.386959   \n",
      "4    0.524141  0.481622  0.328340  ...  0.734543  0.742038  0.803977   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "360  0.761282  0.925290  0.992134  ...  0.133195  0.139146  0.163510   \n",
      "361  0.456304  0.471259  0.483303  ...  0.164056  0.170564  0.203889   \n",
      "362  0.789108  0.806521  0.807998  ...  0.439133  0.222460  0.214460   \n",
      "363  0.581043  0.561596  0.494156  ...  0.623351  0.339824  0.325955   \n",
      "364  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "\n",
      "     col_1194  col_1195  col_1196  col_1197  col_1198  col_1199  col_1200  \n",
      "0    0.322718  0.297691  0.262574  0.250359  0.255128  0.280991  0.358198  \n",
      "1    0.949718  0.958297  0.940590  0.994931  1.000000  1.000000  0.988938  \n",
      "2    0.884184  0.900839  0.859699  0.876662  0.879300  0.928011  0.799627  \n",
      "3    0.420970  0.411488  0.392825  0.405161  0.409676  0.432619  0.439274  \n",
      "4    0.867041  0.851162  0.809817  0.830549  0.843671  0.899149  0.922527  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "360  0.200029  0.221411  0.224691  0.235360  0.246270  0.282345  0.345072  \n",
      "361  0.247077  0.264664  0.269739  0.298033  0.319032  0.329007  0.308227  \n",
      "362  0.228267  0.205816  0.192255  0.217571  0.408695  0.639932  0.729686  \n",
      "363  0.653216  0.715667  0.672569  0.690522  0.542306  0.612178  0.739626  \n",
      "364  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[365 rows x 600 columns]\n",
      "---------------------------------------------\n",
      "Dimensions afther third dimension added:\n",
      "xTrain:\t(178, 600, 1)\n",
      "yTrain:\t(178, 600, 1)\n",
      "xVal:\t(77, 600, 1)\n",
      "yVal:\t(77, 600, 1)\n",
      "xTest:\t(110, 600, 1)\n",
      "yTest:\t(110, 600, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"C:/Users/hecto/Documents/Master/TFM/tfm-renewable-energy-deep-learning/data/2015_1min.xlsx\", header=None, engine='openpyxl')[0]\n",
    "\n",
    "print(df)\n",
    "# Data preprocessing: each row will contain the 10 measures for each day , and the 10 measures for the following day\n",
    "#X = pd.DataFrame(np.array(df).reshape(-1, 10), columns=[\"col_{}\".format(i) for i in range(0, 10)])\n",
    "X = pd.DataFrame(np.array(df).reshape(-1, 600))\n",
    "Y = pd.DataFrame.copy(X)\n",
    "\n",
    "Y.columns = [\"col_{}\".format(i) for i in range(601, 1201)]\n",
    "Y = Y.drop(0)\n",
    "Y = Y.reset_index(drop=True)\n",
    "Y.loc[len(Y)] = np.zeros(600)\n",
    "\n",
    "dfNoNormalized = pd.concat([X, Y], axis=1)\n",
    "\n",
    "dataToPredict = dfNoNormalized.tail(1)\n",
    "print(\"Row for predicting: \", dataToPredict)\n",
    "\n",
    "print(\"DataFrame Preproccessed (Not Normalized):\")\n",
    "print(dfNoNormalized)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# Data Normalization\n",
    "scaler = MinMaxScaler()\n",
    "XNormalized = pd.DataFrame(scaler.fit_transform(X), columns=[\"col_{}\".format(i) for i in range(1, 601)])\n",
    "YNormalized = pd.DataFrame(scaler.fit_transform(Y), columns=[\"col_{}\".format(i) for i in range(601, 1201)])\n",
    "\n",
    "dfPreproccessed = pd.concat([XNormalized, YNormalized], axis=1)\n",
    "\n",
    "# Last row is deleted beacuse it is the one for used for the real prediction, it is not useful for the training of the model.\n",
    "dfPreproccessed.drop(dfNoNormalized.tail(1).index, inplace=True)\n",
    "print(len(dfPreproccessed))\n",
    "\n",
    "print(\"X Preproccessed:\")\n",
    "print(XNormalized)\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Y Preproccessed:\")\n",
    "print(YNormalized)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(XNormalized, YNormalized, test_size = test_size, random_state = 0, shuffle=False)\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(xTrain, yTrain, test_size = val_size, random_state = 0, shuffle=False)\n",
    "\n",
    "# Adding the third dimension needed to use LSTM (samples, timestamps, features)\n",
    "xtrain = np.reshape(xTrain.values, (xTrain.shape[0], xTrain.shape[1], 1))\n",
    "ytrain = np.reshape(yTrain.values, (yTrain.shape[0], yTrain.shape[1], 1))\n",
    "xval = np.reshape(xVal.values, (xVal.shape[0], xVal.shape[1], 1))\n",
    "yval = np.reshape(yVal.values, (yVal.shape[0], yVal.shape[1], 1))\n",
    "xtest = np.reshape(xTest.values, (xTest.shape[0], xTest.shape[1], 1))\n",
    "ytest = np.reshape(yTest.values, (yTest.shape[0], yTest.shape[1], 1))\n",
    "\n",
    "# New shapes after third dimension added\n",
    "print(\"Dimensions afther third dimension added:\")\n",
    "print(\"xTrain:\\t\"+str(xtrain.shape))\n",
    "print(\"yTrain:\\t\"+str(ytrain.shape))\n",
    "print(\"xVal:\\t\"+str(xval.shape))\n",
    "print(\"yVal:\\t\"+str(yval.shape))\n",
    "print(\"xTest:\\t\"+str(xtest.shape))\n",
    "print(\"yTest:\\t\"+str(ytest.shape))\n",
    "\n",
    "validation_data=xval.reshape((xval.shape[0], xval.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (600, 1)\n",
      "Summary: \n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 600)               6600      \n",
      "=================================================================\n",
      "Total params: 7,080\n",
      "Trainable params: 7,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 178 samples, validate on 77 samples\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 4s 23ms/sample\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential_1/lstm_1/StatefulPartitionedCall]] [Op:__inference_distributed_function_3680]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7f33fccbfdd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepchs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         validation_data=(xval.reshape((xval.shape[0], xval.shape[1], 1)), yval))\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;31m# validation_data=(xval,yval))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mc:\\Users\\hecto\\.conda\\envs\\myenv\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential_1/lstm_1/StatefulPartitionedCall]] [Op:__inference_distributed_function_3680]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):    \n",
    "# Model definition\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_nodes, input_shape=(xtrain.shape[1], 1)))\n",
    "    model.add(Dense(600, activation=\"sigmoid\"))\n",
    "\n",
    "    print(\"Input shape\", (xtrain.shape[1], 1))\n",
    "\n",
    "    print(\"Summary: \")\n",
    "    model.summary()\n",
    "\n",
    "    # Model compilation\n",
    "    model.compile(loss=loss,\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[keras.metrics.MAE, keras.metrics.MAPE, keras.metrics.MSE])\n",
    "\n",
    "    history = model.fit(\n",
    "        xtrain.reshape((xtrain.shape[0], xtrain.shape[1], 1)),\n",
    "        ytrain,\n",
    "        epochs=epchs,\n",
    "        batch_size=batch,\n",
    "        validation_data=(xval.reshape((xval.shape[0], xval.shape[1], 1)), yval))\n",
    "            # validation_data=(xval,yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation loss curves\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Model evaluation with validation data\n",
    "score = model.evaluate(xval.reshape((xval.shape[0], xval.shape[1], 1)), yval)\n",
    "print('Score:', score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
