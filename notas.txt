Son 365 días relativos al 2015 y los 366 relativos al 2016. 
De cada día hay 10 horas, que están medidas o cada 30 minutos o cada 1 minuto. 
Por eso el 2015_30min tiene 7300 mediciones (365 dias * 10 horas * 2 mediciones por hora = 72030).

Tenemos:
0
2
3
4
...
7299
Queremos:
Mediciones Dia X, Día Y (Predicción del día X+1)
0, 1, 2, ... 19, y00, y01, y02 ... y019
20, 21, 22, ... 39, y10, y11, y12, .. y119

Bibliografía:
https://www.analyticsvidhya.com/blog/2021/03/introduction-to-long-short-term-memory-lstm/
https://www.kaggle.com/code/carlmcbrideellis/temporal-convolutional-network-using-keras-tcn
https://stackoverflow.com/questions/45278286/how-to-choose-lstm-keras-parameters
https://pypi.org/project/keras-tcn/2.9.3/#arguments
https://keras.io/api/layers/recurrent_layers/gru/
https://keras.io/guides/keras_tuner/getting_started/
https://medium.com/@mlblogging.k/14-loss-functions-you-can-use-for-regression-b24db8dff987

Validation error under training error justification: 
One possibility: If you are using dropout regularization layer in your network, it is reasonable that the validation error is smaller than training error. 
Because usually dropout is activated when training but deactivated when evaluating on the validation set. 
You get a more smooth (usually means better) function in the latter case.