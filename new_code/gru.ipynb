{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting GPU Memory Growth...\n",
      "TF version: 2.1.0\n",
      "KT version: 1.0.1\n",
      "Panda version: 1.1.5\n",
      "Physical devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Default GPU Device: /device:GPU:0\n",
      "Num GPUs Available:  1\n",
      "Build with CUDA:  True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "        print(\"Setting GPU Memory Growth...\")\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        \n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_keras_history import plot_history\n",
    "import sklearn.metrics as metrics\n",
    "import os as os\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import kerastuner as kt\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization\n",
    "\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"KT version:\", kt.__version__)\n",
    "print(\"Panda version:\", pd.__version__)\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(\"Physical devices: \", tf.config.list_physical_devices())\n",
    "# Se va a habilitar la dedicacion dinamica de memoria para que la GPU vaya asignando recursos al proceso conforme los vaya necesitando\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "#print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Build with CUDA: \", tf.test.is_built_with_cuda())\n",
    "\n",
    "# Number of best models\n",
    "numBestModels = 1 \n",
    "\n",
    "# Validation set percentage\n",
    "val_size = 0.3\n",
    "\n",
    "# Batch size\n",
    "batch = 1024\n",
    "\n",
    "# Nodos internos\n",
    "hidden_nodes = 10\n",
    "\n",
    "# Units parameters\n",
    "minUnits = 10\n",
    "maxUnits = 50\n",
    "stepsUnits = 10\n",
    "defaultUnits = 25\n",
    "\n",
    "# Layers parameters\n",
    "minLayers = 1\n",
    "maxLayers = 5\n",
    "defaultLayers = 3\n",
    "\n",
    "# Dropout Parameters\n",
    "minDropout = 0\n",
    "maxDropout = 0.33\n",
    "defaultDropout = .25\n",
    "\n",
    "# Establecer medida de loss\n",
    "loss = \"mean_absolute_error\"\n",
    "\n",
    "# Learning rate\n",
    "learningRate = [0.0, 1e-2, 1e-3, 1e-4]\n",
    "\n",
    "# Model metrics\n",
    "modelMetrics = [keras.metrics.MAE, tf.keras.metrics.RootMeanSquaredError(name = 'rmse')]\n",
    "\n",
    "# Optimizer objetive: error percetange with the validation set \n",
    "objective = kt.Objective('val_mean_absolute_error', 'min')\n",
    "\n",
    "# Maximum model trials and executions\n",
    "trials = 1\n",
    "executions = 1\n",
    "\n",
    "# Model saving parameters\n",
    "workingDirectory = datetime.datetime.fromtimestamp(time.time()).strftime('%d-%m-%Y-%H:%M')\n",
    "# projectName = \"gru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     min_temp_d1  max_temp_d1  rainfall_d1  sun_hours_d1  max_wind_speed_d1  \\\n",
      "0       0.919431     0.699029     0.001095      0.774436           0.261538   \n",
      "1       0.909953     0.621359     0.006572      0.315789           0.369231   \n",
      "2       0.744076     0.684466     0.092004      0.902256           0.230769   \n",
      "3       0.777251     0.582524     0.000000      0.285714           0.138462   \n",
      "4       0.763033     0.650485     0.118291      0.909774           0.338462   \n",
      "..           ...          ...          ...           ...                ...   \n",
      "359     0.862559     0.733010     0.004381      0.060150           0.230769   \n",
      "360     0.696682     0.626214     0.004381      0.383459           0.369231   \n",
      "361     0.620853     0.504854     0.000000      0.616541           0.338462   \n",
      "362     0.649289     0.665049     0.000000      0.872180           0.338462   \n",
      "363     0.663507     0.669903     0.000000      0.857143           0.369231   \n",
      "\n",
      "     temp_9_d1  Rel_hum_9_d1  cloud_cover_d1  wind_speed_9_d1  temp_15_d1  \\\n",
      "0     0.878378      0.581081           0.625         0.003896    0.231441   \n",
      "1     0.819820      0.594595           0.625         0.006817    0.196507   \n",
      "2     0.707207      0.783784           1.000         0.003896    0.203785   \n",
      "3     0.797297      0.472973           0.500         0.006817    0.211063   \n",
      "4     0.761261      0.608108           0.875         0.003896    0.136827   \n",
      "..         ...           ...             ...              ...         ...   \n",
      "359   0.729730      0.445946           0.625         0.000000    0.234352   \n",
      "360   0.819820      0.554054           1.000         0.001948    0.193595   \n",
      "361   0.707207      0.364865           0.750         0.010713    0.168850   \n",
      "362   0.608108      0.364865           0.500         0.008765    0.158661   \n",
      "363   0.734234      0.310811           0.375         0.004869    0.186317   \n",
      "\n",
      "     ...  max_wind_speed_d2  temp_9_d2  Rel_hum_9_d2  cloud_cover_d2  \\\n",
      "0    ...           0.369231   0.819820      0.594595           0.625   \n",
      "1    ...           0.230769   0.707207      0.783784           1.000   \n",
      "2    ...           0.138462   0.797297      0.472973           0.500   \n",
      "3    ...           0.338462   0.761261      0.608108           0.875   \n",
      "4    ...           0.338462   0.765766      0.513514           0.875   \n",
      "..   ...                ...        ...           ...             ...   \n",
      "359  ...           0.369231   0.819820      0.554054           1.000   \n",
      "360  ...           0.338462   0.707207      0.364865           0.750   \n",
      "361  ...           0.338462   0.608108      0.364865           0.500   \n",
      "362  ...           0.369231   0.734234      0.310811           0.375   \n",
      "363  ...           0.292308   0.725225      0.270270           0.875   \n",
      "\n",
      "     wind_speed_9_d2  temp_15_d2  Rel_hum_3_d2  cloud_d2  wind_speed_3_d2  \\\n",
      "0           0.006817    0.196507      0.701031     0.875         0.010743   \n",
      "1           0.003896    0.203785      0.649485     0.750         0.008790   \n",
      "2           0.006817    0.211063      0.536082     0.375         0.010743   \n",
      "3           0.003896    0.136827      0.814433     0.875         0.001953   \n",
      "4           0.012661    0.206696      0.484536     0.375         0.014650   \n",
      "..               ...         ...           ...       ...              ...   \n",
      "359         0.001948    0.193595      0.773196     1.000         0.001953   \n",
      "360         0.010713    0.168850      0.567010     0.875         0.008790   \n",
      "361         0.008765    0.158661      0.515464     0.750         0.008790   \n",
      "362         0.004869    0.186317      0.484536     0.375         0.010743   \n",
      "363         0.004869    0.202329      0.432990     0.125         0.014650   \n",
      "\n",
      "     solar_irr_d2  \n",
      "0          0.7125  \n",
      "1          0.3125  \n",
      "2          0.7750  \n",
      "3          0.2875  \n",
      "4          0.9000  \n",
      "..            ...  \n",
      "359        0.3750  \n",
      "360        0.4250  \n",
      "361        0.4500  \n",
      "362        0.8000  \n",
      "363        0.8375  \n",
      "\n",
      "[364 rows x 28 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     min_temp_d1  max_temp_d1  rainfall_d1  sun_hours_d1  max_wind_speed_d1  \\\n",
      "0       0.620853     0.679612     0.000000      0.894737           0.261538   \n",
      "1       0.739336     0.577670     0.000000      0.067669           0.200000   \n",
      "2       0.620853     0.519417     0.048193      0.037594           0.123077   \n",
      "3       0.720379     0.597087     0.127054      0.000000           0.200000   \n",
      "4       0.691943     0.771845     0.082147      1.000000           0.092308   \n",
      "..           ...          ...          ...           ...                ...   \n",
      "360     0.639810     0.621359     0.007667      0.917293           0.261538   \n",
      "361     0.644550     0.665049     0.001095      0.932331           0.307692   \n",
      "362     0.748815     0.713592     0.000000      0.947368           0.261538   \n",
      "363     0.725118     0.791262     0.000000      0.894737           0.307692   \n",
      "364     0.905213     0.864078     0.000000      0.984962           0.307692   \n",
      "\n",
      "     temp_9_d1  Rel_hum_9_d1  cloud_cover_d1  wind_speed_9_d1  temp_15_d1  \\\n",
      "0     0.716216      0.297297           0.500         0.004869    0.202329   \n",
      "1     0.711712      0.297297           0.125         0.003896    0.203785   \n",
      "2     0.626126      0.540541           0.875         0.000000    0.176128   \n",
      "3     0.612613      0.608108           0.875         0.003896    0.168850   \n",
      "4     0.495495      0.959459           1.000         0.006817    0.103348   \n",
      "..         ...           ...             ...              ...         ...   \n",
      "360   0.774775      0.418919           0.500         0.010713    0.160116   \n",
      "361   0.774775      0.459459           0.500         0.008765    0.196507   \n",
      "362   0.788288      0.364865           0.125         0.004869    0.208151   \n",
      "363   0.797297      0.486486           0.375         0.004869    0.218341   \n",
      "364   0.833333      0.405405           0.125         0.001948    0.227074   \n",
      "\n",
      "     ...  max_wind_speed_d2  temp_9_d2  Rel_hum_9_d2  cloud_cover_d2  \\\n",
      "0    ...           0.200000   0.711712      0.297297           0.125   \n",
      "1    ...           0.123077   0.626126      0.540541           0.875   \n",
      "2    ...           0.200000   0.612613      0.608108           0.875   \n",
      "3    ...           0.092308   0.495495      0.959459           1.000   \n",
      "4    ...           0.261538   0.779279      0.500000           0.125   \n",
      "..   ...                ...        ...           ...             ...   \n",
      "360  ...           0.307692   0.774775      0.459459           0.500   \n",
      "361  ...           0.261538   0.788288      0.364865           0.125   \n",
      "362  ...           0.307692   0.797297      0.486486           0.375   \n",
      "363  ...           0.307692   0.833333      0.405405           0.125   \n",
      "364  ...           0.430769   0.932432      0.459459           0.375   \n",
      "\n",
      "     wind_speed_9_d2  temp_15_d2  Rel_hum_3_d2  cloud_d2  wind_speed_3_d2  \\\n",
      "0           0.003896    0.203785      0.432990     0.500         0.010743   \n",
      "1           0.000000    0.176128      0.556701     0.875         0.008790   \n",
      "2           0.003896    0.168850      0.701031     1.000         0.006837   \n",
      "3           0.006817    0.103348      0.958763     1.000         0.001953   \n",
      "4           0.006817    0.259098      0.412371     0.125         0.010743   \n",
      "..               ...         ...           ...       ...              ...   \n",
      "360         0.008765    0.196507      0.577320     0.375         0.010743   \n",
      "361         0.004869    0.208151      0.463918     0.125         0.008790   \n",
      "362         0.004869    0.218341      0.536082     0.125         0.008790   \n",
      "363         0.001948    0.227074      0.608247     0.125         0.012697   \n",
      "364         0.003896    0.256186      0.577320     0.125         0.012697   \n",
      "\n",
      "     solar_irr_d2  \n",
      "0          0.9500  \n",
      "1          0.4250  \n",
      "2          0.2750  \n",
      "3          0.0250  \n",
      "4          0.9625  \n",
      "..            ...  \n",
      "360        0.7625  \n",
      "361        0.9750  \n",
      "362        0.9625  \n",
      "363        1.0000  \n",
      "364        1.0000  \n",
      "\n",
      "[365 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# X = pd.read_csv(\"C:/Users/hecto/Documents/Master/TFM/tfm-renewable-energy-deep-learning/data/training/2015_PV_W20_H20.csv\",\n",
    "#                        delimiter=\";\")\n",
    "\n",
    "# xTest = pd.read_csv(\"C:/Users/hecto/Documents/Master/TFM/tfm-renewable-energy-deep-learning/data/test/2016_PV_W20_H20.csv\",\n",
    "#                    delimiter=\";\")\n",
    "\n",
    "X = pd.read_csv(\"C:/Users/hecto/Documents/Master/TFM/tfm-renewable-energy-deep-learning/data/training/2015_Weather_W2.csv\",\n",
    "                       delimiter=\",\")\n",
    "\n",
    "xTest = pd.read_csv(\"C:/Users/hecto/Documents/Master/TFM/tfm-renewable-energy-deep-learning/data/test/2016_Weather_W2.csv\",\n",
    "                   delimiter=\",\")\n",
    "\n",
    "print(X)\n",
    "print(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs\n",
    "epchs = 1000\n",
    "\n",
    "W=20\n",
    "H=20\n",
    "PV_index = 14\n",
    "\n",
    "# Number of measurements to predict\n",
    "numPredictions = 1\n",
    "\n",
    "projectName = \"lstm30min2016-1kepochs-rs\"\n",
    "# projectName = \"lstm30min2016-1kepochs-bo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PV_1\n",
      "0    0.919431\n",
      "1    0.909953\n",
      "2    0.744076\n",
      "3    0.777251\n",
      "4    0.763033\n",
      "..        ...\n",
      "359  0.862559\n",
      "360  0.696682\n",
      "361  0.620853\n",
      "362  0.649289\n",
      "363  0.663507\n",
      "\n",
      "[364 rows x 1 columns]\n",
      "         PV_1\n",
      "0    0.909953\n",
      "1    0.744076\n",
      "2    0.777251\n",
      "3    0.763033\n",
      "4    0.720379\n",
      "..        ...\n",
      "359  0.696682\n",
      "360  0.620853\n",
      "361  0.649289\n",
      "362  0.663507\n",
      "363  0.000000\n",
      "\n",
      "[364 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing for W type files:\n",
    "\n",
    "# Filter for PV data\n",
    "X = X.iloc[:, ::PV_index]\n",
    "xTest = xTest.iloc[:, ::PV_index]\n",
    "\n",
    "# Reset column names\n",
    "new_column_names = [f'PV_{i+1}' for i in range(len(X.columns))]\n",
    "X.columns = new_column_names\n",
    "xTest.columns = new_column_names\n",
    "\n",
    "Y = pd.DataFrame.copy(X)\n",
    "yTest = pd.DataFrame.copy(xTest)\n",
    "\n",
    "# Create Y from taking next day data\n",
    "Y = Y.drop(0)\n",
    "Y = Y.reset_index(drop = True)\n",
    "Y.loc[len(Y)] = np.zeros(numPredictions)\n",
    "\n",
    "yTest = yTest.drop(0)\n",
    "yTest = yTest.reset_index(drop = True)\n",
    "yTest.loc[len(yTest)] = np.zeros(numPredictions)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing: each row will contain the 20 measures for each day , and the 10 measures for the following day\n",
    "# X = pd.DataFrame(np.array(training).reshape(-1, W))\n",
    "Y = pd.DataFrame.copy(X)\n",
    "yTest = pd.DataFrame.copy(xTest)\n",
    "\n",
    "Y.columns = [\"col_{}\".format(i) for i in range(W+1, (2*W)+1)]\n",
    "Y = Y.drop(0)\n",
    "Y = Y.reset_index(drop = True)\n",
    "Y.loc[len(Y)] = np.zeros(numPredictions)\n",
    "\n",
    "# Last row is deleted because it is the one used for the real prediction, \n",
    "# it is not useful for the training of the model. \n",
    "X.drop(X.tail(1).index, inplace = True)\n",
    "Y.drop(Y.tail(1).index, inplace = True)\n",
    "\n",
    "print(\"X Preproccessed shape: \", X.shape)\n",
    "print(\"Y Preproccessed shape: \", Y.shape)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "#  Uncomment in order to normalize data\n",
    "# Data Normalization\n",
    "# scaler = MinMaxScaler()\n",
    "# X = pd.DataFrame(scaler.fit_transform(X), columns=[\"col_{}\".format(i) for i in range(1, 21)])\n",
    "# Y = pd.DataFrame(scaler.fit_transform(Y), columns=[\"col_{}\".format(i) for i in range(21, 41)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPreproccessed = pd.concat([X, Y], axis = 1)\n",
    "\n",
    "print(\"DataFrame Preproccessed:\")\n",
    "print(dfPreproccessed)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(X, \n",
    "                                            Y, \n",
    "                                            test_size = val_size, \n",
    "                                            random_state = 0, \n",
    "                                            shuffle=False)\n",
    "\n",
    "# Show subsets shapes\n",
    "print(\"Shapes:\")\n",
    "print(\"xTrain:\\t\"+str(xTrain.shape))\n",
    "print(\"yTrain:\\t\"+str(yTrain.shape))\n",
    "print(\"xVal:\\t\"+str(xVal.shape))\n",
    "print(\"yVal:\\t\"+str(yVal.shape))\n",
    "print(\"xTest:\\t\"+str(xTest.shape))\n",
    "print(\"yTest:\\t\"+str(yTest.shape))\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model definition:\n",
    "with tf.device('/gpu:0'): \n",
    "    \n",
    "    def build_model(hp): \n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        # First layer: GRU. Number of units optimization\n",
    "        model.add(GRU(units = hp.Int('units', \n",
    "                                    min_value = minUnits,\n",
    "                                    max_value = maxUnits, \n",
    "                                    step = stepsUnits,\n",
    "                                    default = defaultUnits),\n",
    "                        return_sequences = False, \n",
    "                        input_shape = (xTrain.shape[1], 1)))\n",
    "\n",
    "        # Second layer: Dropout with percetange optimization\n",
    "        model.add(\n",
    "            Dropout(hp.Float('dropout', \n",
    "                            min_value = minDropout,\n",
    "                            max_value = maxDropout,\n",
    "                            default = defaultDropout)))\n",
    "        \n",
    "        # Last layer:\n",
    "        model.add(Dense(numPredictions))\n",
    "\n",
    "        print(\"Summary: \")\n",
    "        model.summary()\n",
    "\n",
    "        # # Set Epsilon to 1, in order to fix huge MAPE values.\n",
    "        # keras.backend.set_epsilon(1)\n",
    "\n",
    "        # Model compilation: learning rate optimization\n",
    "        model.compile(loss = loss,\n",
    "                    optimizer = keras.optimizers.Adam(hp.Choice('learning_rate', \n",
    "                                                                values = learningRate)),\n",
    "                    metrics = metrics = modelMetrics)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training:\n",
    "with tf.device('/gpu:0'): \n",
    "    # Create optimizer\n",
    "    gruOptimizer = RandomSearch(build_model, \n",
    "                                objective = objective,\n",
    "                                max_trials = trials, \n",
    "                                executions_per_trial = executions,\n",
    "                                project_name = projectName,\n",
    "                                overwrite=True)\n",
    "    # Create optimizer using Bayesian Optimization \n",
    "    # lstmOptimizer = BayesianOptimization(build_model, \n",
    "    #                             objective = objective,\n",
    "    #                             max_trials = trials, \n",
    "    #                             executions_per_trial = executions,\n",
    "    #                             project_name = projectName,\n",
    "    #                             overwrite=True)\n",
    "    \n",
    "    # Search space summary\n",
    "    gruOptimizer.search_space_summary()\n",
    "\n",
    "    # Search execution with epochs\n",
    "    initialTime = time.time()\n",
    "    gruOptimizer.search(x = np.reshape(xTrain.values, (xTrain.shape[0], xTrain.shape[1], 1)),\n",
    "                        y = yTrain, \n",
    "                        epochs = epchs,\n",
    "                        batch_size = batch,\n",
    "                        validation_data=(np.reshape(xVal.values, (xVal.shape[0], xVal.shape[1], 1)), yVal))\n",
    "    finalTime = time.time()\n",
    "\n",
    "    # Results summary\n",
    "    gruOptimizer.results_summary()\n",
    "\n",
    "    # Get best model generated\n",
    "    model = gruOptimizer.get_best_models(num_models = numBestModels)[0]\n",
    "\n",
    "    # Model training with epochs \n",
    "    history = model.fit(\n",
    "                np.reshape(xTrain.values, (xTrain.shape[0], xTrain.shape[1], 1)),\n",
    "                yTrain,\n",
    "                epochs = epchs,\n",
    "                batch_size = batch,\n",
    "                validation_data=(np.reshape(xVal.values, (xVal.shape[0], xVal.shape[1], 1)), yVal))\n",
    "\n",
    "    # Show model info\n",
    "    print(\"Tiempo de entrenamiento (en segundos):\\t\"+str(finalTime - initialTime))\n",
    "    print(\"Tiempo de entrenamiento (en horas):\\t\"+str((finalTime - initialTime)/3600))\n",
    "    print(history.history.keys())\n",
    "    print(model.history.history)\n",
    "    print(model.history.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation loss curves\n",
    "plt.plot(history.history['loss'], label = 'Training loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Model evaluation with validation data\n",
    "score = model.evaluate(np.reshape(xTest.values,(xTest.shape[0], xTest.shape[1], 1)), yTest)\n",
    "print('Score:', score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
