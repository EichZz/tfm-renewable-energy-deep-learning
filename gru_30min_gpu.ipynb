{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python --version\n",
    "# %pip install --upgrade pandas\n",
    "# %pip install openpyxl\n",
    "# %pip install numpy\n",
    "# %pip install scikit-learn\n",
    "# %pip install matplotlib\n",
    "# %pip install plot_keras_history\n",
    "# %pip install tensorflow\n",
    "# %pip install keras-tuner\n",
    "# %pip install -q keras-tcn --no-dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "        print(\"Setting GPU Memory Growth...\")\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        \n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_keras_history import plot_history\n",
    "import sklearn.metrics as metrics\n",
    "import os as os\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.python.client import device_lib\n",
    "import kerastuner as kt\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization\n",
    "\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"KT version:\", kt.__version__)\n",
    "print(\"Panda version:\", pd.__version__)\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(\"Physical devices: \", tf.config.list_physical_devices())\n",
    "# Se va a habilitar la dedicacion dinamica de memoria para que la GPU vaya asignando recursos al proceso conforme los vaya necesitando\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "#print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Build with CUDA: \", tf.test.is_built_with_cuda())\n",
    "\n",
    "# Number of measurements to predict\n",
    "numPredictions = 20\n",
    "\n",
    "# Number of best models\n",
    "numBestModels = 1 \n",
    "\n",
    "\n",
    "# Testing set percentage\n",
    "test_size = 0.3\n",
    "# Validation set percentage\n",
    "val_size = 0.3\n",
    "\n",
    "# Batch size\n",
    "batch = 1024\n",
    "\n",
    "# Nodos internos\n",
    "hidden_nodes = 10\n",
    "\n",
    "# Units parameters\n",
    "minUnits = 50\n",
    "maxUnits = 100\n",
    "stepsUnits = 25\n",
    "defaultUnits = 50\n",
    "\n",
    "# Layers parameters\n",
    "minLayers = 1\n",
    "maxLayers = 10\n",
    "defaultLayers = 3\n",
    "\n",
    "# Dropout Parameters\n",
    "minDropout = 0\n",
    "maxDropout = 0.33\n",
    "defaultDropout = .25\n",
    "\n",
    "# Establecer medida de loss\n",
    "loss = \"mean_absolute_error\"\n",
    "\n",
    "# Learning rate\n",
    "learningRate = [0.0, 1e-2, 1e-3, 1e-4]\n",
    "\n",
    "# Model metrics\n",
    "modelMetrics = [keras.metrics.MAE, keras.metrics.RMSE]\n",
    "\n",
    "# Optimizer objetive: error percetange with the validation set \n",
    "objective = kt.Objective('val_mean_absolute_error', 'min')\n",
    "\n",
    "# Maximum model trials and executions\n",
    "trials = 5\n",
    "executions = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs\n",
    "epchs = 1000\n",
    "projectName = \"gru30min2015-1kepochs-rs\"\n",
    "# projectName = \"gru30min2015-1kepochs-bo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "df = pd.read_excel(\"C:/Users/hecto/Documents/Master/TFM/tfm-renewable-energy-deep-learning/data/2015_30min.xlsx\", \n",
    "                header=None, \n",
    "                engine='openpyxl')[0]\n",
    "\n",
    "df2 = pd.read_excel(\"C:/Users/hecto/Documents/Master/TFM/tfm-renewable-energy-deep-learning/data/2016_30min.xlsx\",\n",
    "                    header = None, \n",
    "                    engine = 'openpyxl')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing: each row will contain the 20 measures for each day , and the 10 measures for the following day\n",
    "X = pd.DataFrame(np.array(df).reshape(-1, 20))\n",
    "Y = pd.DataFrame.copy(X)\n",
    "\n",
    "Y.columns = [\"col_{}\".format(i) for i in range(21, 41)]\n",
    "Y = Y.drop(0)\n",
    "Y = Y.reset_index(drop=True)\n",
    "Y.loc[len(Y)] = np.zeros(numPredictions)\n",
    "\n",
    "# Last row is deleted because it is the one used for the real prediction, \n",
    "# it is not useful for the training of the model. \n",
    "X.drop(X.tail(1).index,inplace=True)\n",
    "Y.drop(Y.tail(1).index,inplace=True)\n",
    "\n",
    "print(\"X Preproccessed shape: \", X.shape)\n",
    "print(\"Y Preproccessed shape: \", Y.shape)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "#  Uncomment in order to normalize data\n",
    "# Data Normalization\n",
    "# scaler = MinMaxScaler()\n",
    "# X = pd.DataFrame(scaler.fit_transform(X), columns=[\"col_{}\".format(i) for i in range(1, 21)])\n",
    "# Y = pd.DataFrame(scaler.fit_transform(Y), columns=[\"col_{}\".format(i) for i in range(21, 41)])\n",
    "\n",
    "dfPreproccessed = pd.concat([X, Y], axis=1)\n",
    "\n",
    "print(\"DataFrame Preproccessed:\")\n",
    "print(dfPreproccessed)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, \n",
    "                                                Y, \n",
    "                                                test_size = test_size, \n",
    "                                                random_state = 0, \n",
    "                                                shuffle=False)\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(xTrain, \n",
    "                                            yTrain, \n",
    "                                            test_size = val_size, \n",
    "                                            random_state = 0,\n",
    "                                            shuffle=False)\n",
    "\n",
    "# Show subsets shapes\n",
    "print(\"Shapes:\")\n",
    "print(\"xTrain:\\t\"+str(xTrain.shape))\n",
    "print(\"yTrain:\\t\"+str(yTrain.shape))\n",
    "print(\"xVal:\\t\"+str(xVal.shape))\n",
    "print(\"yVal:\\t\"+str(yVal.shape))\n",
    "print(\"xTest:\\t\"+str(xTest.shape))\n",
    "print(\"yTest:\\t\"+str(yTest.shape))\n",
    "print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model definition:\n",
    "with tf.device('/gpu:0'): \n",
    "    \n",
    "    def build_model(hp): \n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        # First layer: GRU. Number of units optimization\n",
    "        model.add(GRU(units = hp.Int('units', \n",
    "                                    min_value = minUnits,\n",
    "                                    max_value = maxUnits, \n",
    "                                    step = stepsUnits,\n",
    "                                    default = defaultUnits),\n",
    "                        return_sequences = False, \n",
    "                        input_shape = (xTrain.shape[1], 1)))\n",
    "\n",
    "        # Second layer: Dropout with percetange optimization\n",
    "        model.add(\n",
    "            Dropout(hp.Float('dropout', \n",
    "                            min_value = minDropout,\n",
    "                            max_value = maxDropout,\n",
    "                            default = defaultDropout)))\n",
    "        \n",
    "        # Last layer:\n",
    "        model.add(Dense(numPredictions))\n",
    "\n",
    "        print(\"Summary: \")\n",
    "        model.summary()\n",
    "\n",
    "        # # Set Epsilon to 1, in order to fix huge MAPE values.\n",
    "        # keras.backend.set_epsilon(1)\n",
    "\n",
    "        # Model compilation: learning rate optimization\n",
    "        model.compile(loss = loss,\n",
    "                    optimizer = keras.optimizers.Adam(hp.Choice('learning_rate', \n",
    "                                                                values = learningRate)),\n",
    "                    metrics = metrics = modelMetrics)\n",
    "\n",
    "        return model\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training:\n",
    "with tf.device('/gpu:0'): \n",
    "    # Create optimizer\n",
    "    gruOptimizer = RandomSearch(build_model, \n",
    "                                objective = objective,\n",
    "                                max_trials = trials, \n",
    "                                executions_per_trial = executions,\n",
    "                                project_name = projectName,\n",
    "                                overwrite=True)\n",
    "\n",
    "    # Search space summary\n",
    "    gruOptimizer.search_space_summary()\n",
    "\n",
    "    # Search execution with epochs\n",
    "    initialTime = time.time()\n",
    "    gruOptimizer.search(x = np.reshape(xTrain.values, (xTrain.shape[0], xTrain.shape[1], 1)),\n",
    "                        y = yTrain, \n",
    "                        epochs = epchs,\n",
    "                        batch_size = batch,\n",
    "                        validation_data=(np.reshape(xVal.values, (xVal.shape[0], xVal.shape[1], 1)), yVal))\n",
    "    finalTime = time.time()\n",
    "\n",
    "    # Results summary\n",
    "    gruOptimizer.results_summary()\n",
    "\n",
    "    # Get best model generated\n",
    "    model = gruOptimizer.get_best_models(num_models = numBestModels)[0]\n",
    "\n",
    "    # Model training with epochs \n",
    "    history = model.fit(\n",
    "                np.reshape(xTrain.values, (xTrain.shape[0], xTrain.shape[1], 1)),\n",
    "                yTrain,\n",
    "                epochs = epchs,\n",
    "                batch_size = batch,\n",
    "                validation_data=(np.reshape(xVal.values, (xVal.shape[0], xVal.shape[1], 1)), yVal))\n",
    "\n",
    "    # Show model info\n",
    "    print(\"Tiempo de entrenamiento (en segundos):\\t\"+str(finalTime - initialTime))\n",
    "    print(\"Tiempo de entrenamiento (en horas):\\t\"+str((finalTime - initialTime)/3600))\n",
    "    print(history.history.keys())\n",
    "    print(model.history.history)\n",
    "    print(model.history.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation loss curves\n",
    "plt.plot(history.history['loss'], label = 'Training loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Model evaluation with validation data\n",
    "score = model.evaluate(np.reshape(xTest.values,(xTest.shape[0], xTest.shape[1], 1)), yTest)\n",
    "print('Score:', score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
